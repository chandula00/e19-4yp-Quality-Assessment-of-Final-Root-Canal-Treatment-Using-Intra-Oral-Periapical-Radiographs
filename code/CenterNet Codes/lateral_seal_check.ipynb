{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7c4e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def load_annotations(json_file):\n",
    "    \"\"\"Load the annotation JSON file.\"\"\"\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\"Load an image from the given path.\"\"\"\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        print(\"Error loading image:\", image_path)\n",
    "    return img\n",
    "\n",
    "def apply_clahe_color(image, clip_limit=2.0, tile_grid_size=(8,8)):\n",
    "    \"\"\"\n",
    "    Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "    on the L-channel of the LAB representation to enhance the image details.\n",
    "    \"\"\"\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    cl = clahe.apply(l)\n",
    "    limg = cv2.merge((cl, a, b))\n",
    "    enhanced = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "    return enhanced\n",
    "\n",
    "def scale_points(points, orig_width, orig_height):\n",
    "    \"\"\"\n",
    "    Convert normalized polygon points to pixel coordinates.\n",
    "    Assumes the normalized points are given in percentages.\n",
    "    Adjust the conversion if your points are normalized differently.\n",
    "    \"\"\"\n",
    "    scaled = []\n",
    "    for pt in points:\n",
    "        # If points are in [x_percent, y_percent] format (0-100)\n",
    "        x = int(pt[0])\n",
    "        y = int(pt[1])\n",
    "        scaled.append([x, y])\n",
    "    return scaled\n",
    "\n",
    "def create_mask_for_polygon(img_shape, points):\n",
    "    \"\"\"\n",
    "    Create a binary mask from a list of polygon points.\n",
    "    The mask will have the same height and width as the input image.\n",
    "    \"\"\"\n",
    "    pts = np.array(points, dtype=np.int32)\n",
    "    mask = np.zeros(img_shape[:2], dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, [pts], 255)\n",
    "    return mask\n",
    "\n",
    "def create_border_regions(mask, range_pixels):\n",
    "    \"\"\"\n",
    "    Given a binary mask, create inner and outer border regions using\n",
    "    morphological erosion and dilation.\n",
    "    \n",
    "    - inner_border: region lost when eroding the mask by 'range_pixels'\n",
    "    - outer_border: additional region gained when dilating the mask by 'range_pixels'\n",
    "    \n",
    "    Note: 'range_pixels' is an approximation for 2mm in pixels. Adjust as needed.\n",
    "    \"\"\"\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    eroded = cv2.erode(mask, kernel, iterations=range_pixels)\n",
    "    dilated = cv2.dilate(mask, kernel, iterations=range_pixels)\n",
    "    \n",
    "    inner_border = cv2.subtract(mask, eroded)\n",
    "    outer_border = cv2.subtract(dilated, mask)\n",
    "    return inner_border, outer_border\n",
    "\n",
    "def analyze_intensities(image, mask, inner_border, outer_border):\n",
    "    \"\"\"\n",
    "    Analyze average grayscale intensities in:\n",
    "      - The filling region (mask)\n",
    "      - The inner border (edge within the filling)\n",
    "      - The outer border (just outside the filling)\n",
    "      \n",
    "    The analysis is done on a grayscale version of the image.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    filling_values = gray[mask == 255]\n",
    "    inner_values = gray[inner_border == 255]\n",
    "    outer_values = gray[outer_border == 255]\n",
    "    \n",
    "    avg_filling = np.mean(filling_values) if filling_values.size > 0 else 0\n",
    "    avg_inner = np.mean(inner_values) if inner_values.size > 0 else 0\n",
    "    avg_outer = np.mean(outer_values) if outer_values.size > 0 else 0\n",
    "    \n",
    "    return avg_filling, avg_inner, avg_outer\n",
    "\n",
    "def overlay_annotation(image, points, color=(0, 255, 0), alpha=0.4):\n",
    "    \"\"\"\n",
    "    Overlay a filled polygon with transparency on the image.\n",
    "    \"\"\"\n",
    "    overlay = image.copy()\n",
    "    pts = np.array(points, dtype=np.int32)\n",
    "    cv2.fillPoly(overlay, [pts], color)\n",
    "    combined = cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0)\n",
    "    return combined\n",
    "\n",
    "def overlay_mask(image, mask, color=(255, 0, 0), alpha=0.4):\n",
    "    \"\"\"\n",
    "    Overlay a binary mask on the image with a specified color and transparency.\n",
    "    \"\"\"\n",
    "    overlay = image.copy()\n",
    "    overlay[mask == 255] = color\n",
    "    combined = cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0)\n",
    "    return combined\n",
    "\n",
    "def mark_low_intensity_pixels(image, outer_mask, threshold=200, mark_color=(0, 0, 255), alpha=0.5):\n",
    "    \"\"\"\n",
    "    Mark pixels in the outer edge region (outer_mask) where the grayscale intensity\n",
    "    is less than the specified threshold.\n",
    "    \n",
    "    The pixels are marked with the provided mark_color.\n",
    "    \n",
    "    Returns:\n",
    "        - The image with marked low-intensity pixels\n",
    "        - The count of low-intensity pixels\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Create a boolean mask for pixels in outer_mask with intensity less than threshold\n",
    "    low_intensity_mask = (outer_mask == 255) & (gray < threshold)\n",
    "    \n",
    "    # Count the number of low-intensity pixels\n",
    "    low_intensity_pixel_count = np.sum(low_intensity_mask)\n",
    "    \n",
    "    marked = image.copy()\n",
    "    # Mark these pixels with mark_color\n",
    "    marked[low_intensity_mask] = mark_color\n",
    "    combined = cv2.addWeighted(marked, alpha, image, 1 - alpha, 0)\n",
    "    \n",
    "    return combined, low_intensity_pixel_count\n",
    "\n",
    "def compute_intensity_profile(image, mask, inner_pixels=8, outer_pixels=10):\n",
    "    \"\"\"\n",
    "    Compute the average grayscale intensity in 1-pixel-wide bins\n",
    "    from inner_pixels inside (-ve) to outer_pixels outside (+ve).\n",
    "    \n",
    "    Returns:\n",
    "        - bins: List of distances from the boundary\n",
    "        - intensity_profile: Mean grayscale intensity per bin\n",
    "        - bin_masks: Dictionary mapping bin indices to pixel masks\n",
    "    \"\"\"\n",
    "    bins = np.arange(-inner_pixels, outer_pixels + 1, 1)\n",
    "    intensity_profile = []\n",
    "    bin_masks = {}  # Store masks for each bin\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "\n",
    "    for b in bins:\n",
    "        if b < 0:\n",
    "            eroded_1 = cv2.erode(mask, kernel, iterations=abs(b))\n",
    "            border_1 = cv2.subtract(mask, eroded_1)\n",
    "\n",
    "            eroded_2 = cv2.erode(mask, kernel, iterations=abs(b) + 1)\n",
    "            border_2 = cv2.subtract(mask, eroded_2)\n",
    "\n",
    "            border = cv2.subtract(border_2, border_1)\n",
    "        else:\n",
    "            dilated_1 = cv2.dilate(mask, kernel, iterations=b)\n",
    "            border_1 = cv2.subtract(dilated_1, mask)\n",
    "\n",
    "            dilated_2 = cv2.dilate(mask, kernel, iterations=b + 1)\n",
    "            border_2 = cv2.subtract(dilated_2, mask)\n",
    "\n",
    "            border = cv2.subtract(border_2, border_1)\n",
    "\n",
    "        # Use grayscale for intensity measurement\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        values = gray[border == 255]\n",
    "        \n",
    "        mean_intensity = np.mean(values) if values.size > 0 else 0\n",
    "        intensity_profile.append(mean_intensity)\n",
    "        bin_masks[b] = border  # Store the mask for this bin\n",
    "    \n",
    "    return bins, intensity_profile, bin_masks\n",
    "\n",
    "# Visualization function (edited to show only \"lateral_seal\" for \"Filling\")\n",
    "def visualize(image_path, annotations, title=\"\"):\n",
    "    image = Image.open(image_path)\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    for ann in annotations:\n",
    "        shape = ann.get(\"shape\")\n",
    "        coords = ann.get(\"annotations\", [])\n",
    "        name = ann.get(\"name\")\n",
    "\n",
    "        if shape == \"polygon\" and name == \"Filling\" and len(coords) >= 4:\n",
    "            points = [(coords[i], coords[i+1]) for i in range(0, len(coords), 2)]\n",
    "            poly = patches.Polygon(points, closed=True, fill=False, edgecolor='red', linewidth=2)\n",
    "            ax.add_patch(poly)\n",
    "            ax.text(points[0][0], points[0][1], name, color='red', fontsize=9)\n",
    "            \n",
    "            lateral_seal = ann.get(\"lateral_seal\", \"\")\n",
    "            if lateral_seal:\n",
    "                ax.text(points[0][0], points[0][1]+15, f\"Lateral Seal: {lateral_seal}\", color='blue', fontsize=8)\n",
    "\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Define file names and parameters\n",
    "    json_file = \"annotated_and_labeled.json\"\n",
    "    image_dir = \"annotated_and_labeled\" # Directory containing the images\n",
    "    range_pixels = 10  # Approximate pixel distance for a 2mm range (adjust as needed)\n",
    "    \n",
    "    # Load annotation JSON and image\n",
    "    data = load_annotations(json_file)\n",
    "\n",
    "    print(f\"Loaded {len(data)} entries from {json_file}\")\n",
    "\n",
    "    for entry in data:\n",
    "        annotations = entry.get(\"annotation\", [])\n",
    "        has_valid_filling = any(\n",
    "            ann.get(\"shape\") == \"polygon\" and \n",
    "            ann.get(\"name\") == \"Filling\" and \n",
    "            len(ann.get(\"annotations\", [])) >= 4\n",
    "            for ann in annotations\n",
    "        )\n",
    "\n",
    "        if has_valid_filling:\n",
    "            img_path = os.path.join(image_dir, entry[\"image_name\"])\n",
    "            # Print the image name for debugging\n",
    "            print(f\"Visualizing: {entry['image_name']}\")\n",
    "            \n",
    "            # Check if the image file exists before visualizing\n",
    "            if os.path.exists(img_path):\n",
    "                visualize(img_path, annotations, title=entry[\"image_name\"])\n",
    "\n",
    "        annotations = entry.get('annotation', [])\n",
    "        has_valid_filling = any(\n",
    "            ann.get(\"shape\") == \"polygon\" and \n",
    "            ann.get(\"name\") == \"Filling\" and \n",
    "            len(ann.get(\"annotations\", [])) >= 4\n",
    "            for ann in annotations\n",
    "        )\n",
    "\n",
    "        # Check if there are any valid filling annotations\n",
    "        if not has_valid_filling:\n",
    "            print(f\"No valid filling annotations found for {entry['image_name']}\")\n",
    "            for ann in annotations:\n",
    "                print(ann.get(\"shape\"), ann.get(\"name\"), len(ann.get(\"annotations\", [])))\n",
    "            continue\n",
    "\n",
    "        if has_valid_filling:\n",
    "            print(f\"Visualizing: {entry['image_name']}\")\n",
    "            img_path = os.path.join(image_dir, entry[\"image_name\"])\n",
    "\n",
    "            # check if the image exists\n",
    "            if os.path.exists(img_path):\n",
    "                image = load_image(img_path)\n",
    "\n",
    "\n",
    "                # Enhance the image using CLAHE\n",
    "                enhanced_image = apply_clahe_color(image)\n",
    "                # enhanced_image = image\n",
    "                \n",
    "                results = []\n",
    "                \n",
    "                # Process each annotation (each root filling polygon)\n",
    "                for ann in annotations:\n",
    "                    shape = ann.get(\"shape\")\n",
    "                    coords = ann.get(\"annotations\", [])\n",
    "                    name = ann.get(\"name\")\n",
    "                    if shape == \"polygon\" and name == \"Filling\" and len(coords) >= 4:\n",
    "                        points = coords\n",
    "                        # print(f\"Processing annotation for {name}: {points}\")\n",
    "\n",
    "                        # Convert flat list to list of [x, y] pairs\n",
    "                        points_xy = [[points[i], points[i+1]] for i in range(0, len(points), 2)]\n",
    "                        scaled_points = scale_points(points_xy, image.shape[1], image.shape[0])\n",
    "                        # print(f\"Scaled points for {name}: {scaled_points}\")\n",
    "\n",
    "                        # Create the filled region mask\n",
    "                        mask = create_mask_for_polygon(image.shape, scaled_points)\n",
    "\n",
    "                        # Create border regions (inner and outer)\n",
    "                        inner_border, outer_border = create_border_regions(mask, range_pixels)\n",
    "\n",
    "                        # Analyze the average intensity in filling region and border regions\n",
    "                        avg_filling, avg_inner, avg_outer = analyze_intensities(enhanced_image, mask, inner_border, outer_border)\n",
    "                        results.append({\n",
    "                            'label': name,\n",
    "                            'avg_filling': avg_filling,\n",
    "                            'avg_inner': avg_inner,\n",
    "                            'avg_outer': avg_outer,\n",
    "                            'mask': mask,\n",
    "                            'inner_border': inner_border,\n",
    "                            'outer_border': outer_border,\n",
    "                            'scaled_points': scaled_points\n",
    "                        })\n",
    "\n",
    "                        \n",
    "                        # Overlay the filled annotation region (with transparency) on the enhanced image\n",
    "                        annotated_img = overlay_annotation(enhanced_image, scaled_points, color=(0, 255, 0), alpha=0.4)\n",
    "                        \n",
    "                        # Highlight the outer edge region in red using overlay_mask\n",
    "                        outer_edge_overlay = overlay_mask(enhanced_image, outer_border, color=(255, 0, 0), alpha=0.4)\n",
    "                        outer_edge_overlay = overlay_mask(enhanced_image, outer_border, color=(255, 0, 0), alpha=0.4)\n",
    "                        \n",
    "                        # Get count of low-intensity pixels\n",
    "                        low_intensity_marked, low_intensity_pixel_count = mark_low_intensity_pixels(\n",
    "                            enhanced_image, outer_border, threshold=160, mark_color=(0, 0, 255), alpha=0.6\n",
    "                        )\n",
    "\n",
    "                        # Count pixels in the filled annotation region\n",
    "                        filled_pixel_count = np.sum(mask == 255)\n",
    "\n",
    "\n",
    "                        # Display the images\n",
    "                        plt.figure(figsize=(36, 10))\n",
    "                        plt.subplot(1, 4, 1)\n",
    "                        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "                        plt.title(\"Original Image\")\n",
    "                        plt.axis(\"off\")\n",
    "                        \n",
    "                        plt.subplot(1, 4, 2)\n",
    "                        plt.imshow(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))\n",
    "                        plt.title(f\"Annotation Filled \")\n",
    "                        plt.axis(\"off\")\n",
    "                        \n",
    "                        plt.subplot(1, 4, 3)\n",
    "                        plt.imshow(cv2.cvtColor(outer_edge_overlay, cv2.COLOR_BGR2RGB))\n",
    "                        plt.title(f\"Outer Edge Region \")\n",
    "                        plt.axis(\"off\")\n",
    "                        \n",
    "                        # plt.subplot(1, 4, 4)\n",
    "                        # plt.imshow(cv2.cvtColor(low_intensity_marked, cv2.COLOR_BGR2RGB))\n",
    "                        # plt.title(\"Low Intensity Marked\\n(Outer Edge)\")\n",
    "                        # plt.axis(\"off\")\n",
    "                        # plt.show()\n",
    "                        \n",
    "                        print(f\"Results for:\")\n",
    "                        print(f\"  Average intensity in filling region: {avg_filling:.2f}\")\n",
    "                        print(f\"  Average intensity in inner border (edge inside): {avg_inner:.2f}\")\n",
    "                        print(f\"  Average intensity in outer border (edge outside): {avg_outer:.2f}\")\n",
    "                        print(\"-\" * 50)\n",
    "                        \n",
    "                        # Compute intensity profile\n",
    "                        bins, intensity_profile, bin_masks = compute_intensity_profile(enhanced_image, mask, inner_pixels=8, outer_pixels=10)\n",
    "\n",
    "                        # Step 1: Compute the mean intensity for bins 7 to 10\n",
    "                        ref_bins = np.arange(7, 11)  # Bins from 7 to 10\n",
    "                        # Use numpy for safe indexing\n",
    "                        ref_indices = np.where(np.isin(bins, ref_bins))[0]\n",
    "                        ref_intensities = [intensity_profile[i] for i in ref_indices]\n",
    "                        mean_ref_intensity = np.mean(ref_intensities)\n",
    "\n",
    "                        # Step 2: Identify bins where intensity is lower than mean_ref_intensity\n",
    "                        composite_mask = np.zeros_like(mask)  # Initialize empty mask\n",
    "                        for i, intensity in enumerate(intensity_profile):\n",
    "                            bin_idx = bins[i]\n",
    "                            if intensity < mean_ref_intensity - 4:  # Threshold for lower intensity\n",
    "                                composite_mask = cv2.bitwise_or(composite_mask, bin_masks[bin_idx])\n",
    "\n",
    "                        # Step 3: Identify pixels in composite border that have intensity < mean_ref_intensity\n",
    "                        gray = cv2.cvtColor(enhanced_image, cv2.COLOR_BGR2GRAY)\n",
    "                        low_intensity_mask = (composite_mask == 255) & (gray < mean_ref_intensity)\n",
    "\n",
    "\n",
    "                        # Step 4: Count and calculate percentage\n",
    "                        low_intensity_pixel_count = np.sum(low_intensity_mask)\n",
    "                        total_composite_pixels = np.sum(composite_mask == 255)\n",
    "                        low_intensity_percentage = (low_intensity_pixel_count / total_composite_pixels) * 100 if total_composite_pixels > 0 else 0\n",
    "\n",
    "                        print(f\"Percentage of low-intensity pixels in composite border: {low_intensity_percentage:.2f}%\")\n",
    "\n",
    "                        # Compute the percentage\n",
    "                        total_relevant_pixels = filled_pixel_count + low_intensity_pixel_count\n",
    "                        low_intensity_percentage = (low_intensity_pixel_count / total_relevant_pixels) * 100 if total_relevant_pixels > 0 else 0\n",
    "\n",
    "                        # print(filled_pixel_count, low_intensity_pixel_count, total_relevant_pixels, low_intensity_percentage)\n",
    "\n",
    "                        print(f\"Percentage of low-intensity pixels in outer region of : {low_intensity_percentage:.2f}%\")\n",
    "\n",
    "                        # Step 5: Visualize the composite mask and low-intensity pixels\n",
    "                        marked = enhanced_image.copy()\n",
    "                        marked[low_intensity_mask] = (0, 0, 255)  # Mark low-intensity pixels in red\n",
    "                        plt.subplot(1, 4, 4)\n",
    "                        plt.imshow(cv2.cvtColor(marked, cv2.COLOR_BGR2RGB))\n",
    "                        plt.title(\"Low Intensity Pixels in Composite Border\")\n",
    "                        plt.axis(\"off\")\n",
    "                        plt.show()\n",
    "                        \n",
    "                        # Plot the intensity profile\n",
    "                        plt.figure(figsize=(8, 5))\n",
    "                        plt.plot(bins, intensity_profile, marker='o', linestyle='-')\n",
    "                        plt.xlabel('Distance (pixels)\\n(Negative: inside, 0: boundary, Positive: outside)')\n",
    "                        plt.ylabel('Average Grayscale Intensity')\n",
    "                        plt.title(f'Intensity Profile Across Border')\n",
    "                        plt.grid(True)\n",
    "                        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e17d45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "VISUALIZE_PLOTS = False  # Set to True to enable visualization\n",
    "\n",
    "def load_annotations(json_file):\n",
    "    \"\"\"Load the annotation JSON file.\"\"\"\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\"Load an image from the given path.\"\"\"\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        print(\"Error loading image:\", image_path)\n",
    "    return img\n",
    "\n",
    "def apply_clahe_color(image, clip_limit=2.0, tile_grid_size=(8,8)):\n",
    "    \"\"\"\n",
    "    Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "    on the L-channel of the LAB representation to enhance the image details.\n",
    "    \"\"\"\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    cl = clahe.apply(l)\n",
    "    limg = cv2.merge((cl, a, b))\n",
    "    enhanced = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "    return enhanced\n",
    "\n",
    "def scale_points(points, orig_width, orig_height):\n",
    "    \"\"\"\n",
    "    Convert normalized polygon points to pixel coordinates.\n",
    "    Assumes the normalized points are given in pixels already.\n",
    "    \"\"\"\n",
    "    scaled = []\n",
    "    for pt in points:\n",
    "        # If points are in [x, y] format (already in pixels)\n",
    "        x = int(pt[0])\n",
    "        y = int(pt[1])\n",
    "        scaled.append([x, y])\n",
    "    return scaled\n",
    "\n",
    "def create_mask_for_polygon(img_shape, points):\n",
    "    \"\"\"\n",
    "    Create a binary mask from a list of polygon points.\n",
    "    The mask will have the same height and width as the input image.\n",
    "    \"\"\"\n",
    "    pts = np.array(points, dtype=np.int32)\n",
    "    mask = np.zeros(img_shape[:2], dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, [pts], 255)\n",
    "    return mask\n",
    "\n",
    "def create_border_regions(mask, range_pixels):\n",
    "    \"\"\"\n",
    "    Given a binary mask, create inner and outer border regions using\n",
    "    morphological erosion and dilation.\n",
    "    \n",
    "    - inner_border: region lost when eroding the mask by 'range_pixels'\n",
    "    - outer_border: additional region gained when dilating the mask by 'range_pixels'\n",
    "    \n",
    "    Note: 'range_pixels' is an approximation for 2mm in pixels. Adjust as needed.\n",
    "    \"\"\"\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    eroded = cv2.erode(mask, kernel, iterations=range_pixels)\n",
    "    dilated = cv2.dilate(mask, kernel, iterations=range_pixels)\n",
    "    \n",
    "    inner_border = cv2.subtract(mask, eroded)\n",
    "    outer_border = cv2.subtract(dilated, mask)\n",
    "    return inner_border, outer_border\n",
    "\n",
    "def analyze_intensities(image, mask, inner_border, outer_border):\n",
    "    \"\"\"\n",
    "    Analyze average grayscale intensities in:\n",
    "      - The filling region (mask)\n",
    "      - The inner border (edge within the filling)\n",
    "      - The outer border (just outside the filling)\n",
    "      \n",
    "    The analysis is done on a grayscale version of the image.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    filling_values = gray[mask == 255]\n",
    "    inner_values = gray[inner_border == 255]\n",
    "    outer_values = gray[outer_border == 255]\n",
    "    \n",
    "    avg_filling = np.mean(filling_values) if filling_values.size > 0 else 0\n",
    "    avg_inner = np.mean(inner_values) if inner_values.size > 0 else 0\n",
    "    avg_outer = np.mean(outer_values) if outer_values.size > 0 else 0\n",
    "    \n",
    "    return avg_filling, avg_inner, avg_outer\n",
    "\n",
    "def overlay_annotation(image, points, color=(0, 255, 0), alpha=0.4):\n",
    "    \"\"\"\n",
    "    Overlay a filled polygon with transparency on the image.\n",
    "    \"\"\"\n",
    "    overlay = image.copy()\n",
    "    pts = np.array(points, dtype=np.int32)\n",
    "    cv2.fillPoly(overlay, [pts], color)\n",
    "    combined = cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0)\n",
    "    return combined\n",
    "\n",
    "def overlay_mask(image, mask, color=(255, 0, 0), alpha=0.4):\n",
    "    \"\"\"\n",
    "    Overlay a binary mask on the image with a specified color and transparency.\n",
    "    \"\"\"\n",
    "    overlay = image.copy()\n",
    "    overlay[mask == 255] = color\n",
    "    combined = cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0)\n",
    "    return combined\n",
    "\n",
    "def mark_low_intensity_pixels(image, outer_mask, threshold=200, mark_color=(0, 0, 255), alpha=0.5):\n",
    "    \"\"\"\n",
    "    Mark pixels in the outer edge region (outer_mask) where the grayscale intensity\n",
    "    is less than the specified threshold.\n",
    "    \n",
    "    The pixels are marked with the provided mark_color.\n",
    "    \n",
    "    Returns:\n",
    "        - The image with marked low-intensity pixels\n",
    "        - The count of low-intensity pixels\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Create a boolean mask for pixels in outer_mask with intensity less than threshold\n",
    "    low_intensity_mask = (outer_mask == 255) & (gray < threshold)\n",
    "    \n",
    "    # Count the number of low-intensity pixels\n",
    "    low_intensity_pixel_count = np.sum(low_intensity_mask)\n",
    "    \n",
    "    marked = image.copy()\n",
    "    # Mark these pixels with mark_color\n",
    "    marked[low_intensity_mask] = mark_color\n",
    "    combined = cv2.addWeighted(marked, alpha, image, 1 - alpha, 0)\n",
    "    \n",
    "    return combined, low_intensity_pixel_count\n",
    "\n",
    "def compute_intensity_profile(image, mask, inner_pixels=6, outer_pixels=11):\n",
    "    \"\"\"\n",
    "    Compute the average grayscale intensity in 1-pixel-wide bins\n",
    "    from inner_pixels inside (-ve) to outer_pixels outside (+ve).\n",
    "    \n",
    "    Returns:\n",
    "        - bins: List of distances from the boundary\n",
    "        - intensity_profile: Mean grayscale intensity per bin\n",
    "        - bin_masks: Dictionary mapping bin indices to pixel masks\n",
    "    \"\"\"\n",
    "    bins = np.arange(-inner_pixels, outer_pixels + 1, 1)\n",
    "    intensity_profile = []\n",
    "    bin_masks = {}  # Store masks for each bin\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "\n",
    "    for b in bins:\n",
    "        if b < 0:\n",
    "            eroded_1 = cv2.erode(mask, kernel, iterations=abs(b))\n",
    "            border_1 = cv2.subtract(mask, eroded_1)\n",
    "\n",
    "            eroded_2 = cv2.erode(mask, kernel, iterations=abs(b) + 1)\n",
    "            border_2 = cv2.subtract(mask, eroded_2)\n",
    "\n",
    "            border = cv2.subtract(border_2, border_1)\n",
    "        else:\n",
    "            dilated_1 = cv2.dilate(mask, kernel, iterations=b)\n",
    "            border_1 = cv2.subtract(dilated_1, mask)\n",
    "\n",
    "            dilated_2 = cv2.dilate(mask, kernel, iterations=b + 1)\n",
    "            border_2 = cv2.subtract(dilated_2, mask)\n",
    "\n",
    "            border = cv2.subtract(border_2, border_1)\n",
    "\n",
    "        # Use grayscale for intensity measurement\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        values = gray[border == 255]\n",
    "        \n",
    "        mean_intensity = np.mean(values) if values.size > 0 else 0\n",
    "        intensity_profile.append(mean_intensity)\n",
    "        bin_masks[b] = border  # Store the mask for this bin\n",
    "    \n",
    "    return bins, intensity_profile, bin_masks\n",
    "\n",
    "# Visualization function (edited to show only \"lateral_seal\" for \"Filling\")\n",
    "def visualize(image_path, annotations, title=\"\"):\n",
    "    image = Image.open(image_path)\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    for ann in annotations:\n",
    "        shape = ann.get(\"shape\")\n",
    "        coords = ann.get(\"annotations\", [])\n",
    "        name = ann.get(\"name\")\n",
    "\n",
    "        if shape == \"polygon\" and name == \"Filling\" and len(coords) >= 4:\n",
    "            points = [(coords[i], coords[i+1]) for i in range(0, len(coords), 2)]\n",
    "            poly = patches.Polygon(points, closed=True, fill=False, edgecolor='red', linewidth=2)\n",
    "            ax.add_patch(poly)\n",
    "            ax.text(points[0][0], points[0][1], name, color='red', fontsize=9)\n",
    "            \n",
    "            lateral_seal = ann.get(\"lateral_seal\", \"\")\n",
    "            if lateral_seal:\n",
    "                ax.text(points[0][0], points[0][1]+15, f\"Lateral Seal: {lateral_seal}\", color='blue', fontsize=8)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Define file names and parameters\n",
    "    json_file = \"annotated_and_labeled.json\"\n",
    "    image_dir = \"annotated_and_labeled\" # Directory containing the images\n",
    "    range_pixels = 8  # Approximate pixel distance for a 2mm range (adjust as needed)\n",
    "    \n",
    "    # Load annotation JSON and image\n",
    "    data = load_annotations(json_file)\n",
    "\n",
    "    print(f\"Loaded {len(data)} entries from {json_file}\")\n",
    "\n",
    "    y_true = []  # Ground truth\n",
    "    y_pred = []  # Prediction\n",
    "\n",
    "    for entry in data:\n",
    "        annotations = entry.get(\"annotation\", [])\n",
    "        has_valid_filling = any(\n",
    "            ann.get(\"shape\") == \"polygon\" and \n",
    "            ann.get(\"name\") == \"Filling\" and \n",
    "            len(ann.get(\"annotations\", [])) >= 4\n",
    "            for ann in annotations\n",
    "        )\n",
    "\n",
    "        if has_valid_filling:\n",
    "            img_path = os.path.join(image_dir, entry[\"image_name\"])\n",
    "            # Print the image name for debugging\n",
    "            # print(f\"Visualizing: {entry['image_name']}\")\n",
    "            \n",
    "            # Check if the image file exists before visualizing\n",
    "            if os.path.exists(img_path) and VISUALIZE_PLOTS:\n",
    "                visualize(img_path, annotations, title=entry[\"image_name\"])\n",
    "\n",
    "        # Check if there are any valid filling annotations\n",
    "        if not has_valid_filling:\n",
    "            print(f\"No valid filling annotations found for {entry['image_name']}\")\n",
    "            for ann in annotations:\n",
    "                print(ann.get(\"shape\"), ann.get(\"name\"), len(ann.get(\"annotations\", [])))\n",
    "            continue\n",
    "\n",
    "        if has_valid_filling:\n",
    "            img_path = os.path.join(image_dir, entry[\"image_name\"])\n",
    "\n",
    "            # check if the image exists\n",
    "            if os.path.exists(img_path):\n",
    "                image = load_image(img_path)\n",
    "\n",
    "                # Enhance the image using CLAHE\n",
    "                enhanced_image = apply_clahe_color(image)\n",
    "                # enhanced_image = image\n",
    "                \n",
    "                results = []\n",
    "                \n",
    "                # Process each annotation (each root filling polygon)\n",
    "                for ann in annotations:\n",
    "                    shape = ann.get(\"shape\")\n",
    "                    coords = ann.get(\"annotations\", [])\n",
    "                    name = ann.get(\"name\")\n",
    "                    if shape == \"polygon\" and name == \"Filling\" and len(coords) >= 4:\n",
    "                        points = coords\n",
    "\n",
    "                        # Convert flat list to list of [x, y] pairs\n",
    "                        points_xy = [[points[i], points[i+1]] for i in range(0, len(points), 2)]\n",
    "                        scaled_points = scale_points(points_xy, image.shape[1], image.shape[0])\n",
    "\n",
    "                        # Create the filled region mask\n",
    "                        mask = create_mask_for_polygon(image.shape, scaled_points)\n",
    "\n",
    "                        # Create border regions (inner and outer)\n",
    "                        inner_border, outer_border = create_border_regions(mask, range_pixels)\n",
    "\n",
    "                        # Analyze the average intensity in filling region and border regions\n",
    "                        avg_filling, avg_inner, avg_outer = analyze_intensities(enhanced_image, mask, inner_border, outer_border)\n",
    "                        results.append({\n",
    "                            'label': name,\n",
    "                            'avg_filling': avg_filling,\n",
    "                            'avg_inner': avg_inner,\n",
    "                            'avg_outer': avg_outer,\n",
    "                            'mask': mask,\n",
    "                            'inner_border': inner_border,\n",
    "                            'outer_border': outer_border,\n",
    "                            'scaled_points': scaled_points\n",
    "                        })\n",
    "\n",
    "                        # Overlay the filled annotation region (with transparency) on the enhanced image\n",
    "                        annotated_img = overlay_annotation(enhanced_image, scaled_points, color=(0, 255, 0), alpha=0.4)\n",
    "                        \n",
    "                        # Highlight the outer edge region in red using overlay_mask\n",
    "                        outer_edge_overlay = overlay_mask(enhanced_image, outer_border, color=(255, 0, 0), alpha=0.4)\n",
    "                        \n",
    "                        # Get count of low-intensity pixels\n",
    "                        low_intensity_marked, low_intensity_pixel_count = mark_low_intensity_pixels(\n",
    "                            enhanced_image, outer_border, threshold=160, mark_color=(0, 0, 255), alpha=0.6\n",
    "                        )\n",
    "\n",
    "                        # Count pixels in the filled annotation region\n",
    "                        filled_pixel_count = np.sum(mask == 255)\n",
    "\n",
    "                        # Display the images\n",
    "                        if VISUALIZE_PLOTS:\n",
    "                            plt.figure(figsize=(36, 10))\n",
    "                            plt.subplot(1, 4, 1)\n",
    "                            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "                            plt.title(\"Original Image\")\n",
    "                            plt.axis(\"off\")\n",
    "                            \n",
    "                            plt.subplot(1, 4, 2)\n",
    "                            plt.imshow(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))\n",
    "                            plt.title(f\"Annotation Filled \")\n",
    "                            plt.axis(\"off\")\n",
    "                            \n",
    "                            plt.subplot(1, 4, 3)\n",
    "                            plt.imshow(cv2.cvtColor(outer_edge_overlay, cv2.COLOR_BGR2RGB))\n",
    "                            plt.title(f\"Outer Edge Region \")\n",
    "                            plt.axis(\"off\")\n",
    "                            \n",
    "                            # plt.subplot(1, 4, 4)\n",
    "                            # plt.imshow(cv2.cvtColor(low_intensity_marked, cv2.COLOR_BGR2RGB))\n",
    "                            # plt.title(\"Low Intensity Marked\\n(Outer Edge)\")\n",
    "                            # plt.axis(\"off\")\n",
    "                            # plt.show()\n",
    "                            \n",
    "                            print(f\"Results for:\")\n",
    "                            print(f\"  Average intensity in filling region: {avg_filling:.2f}\")\n",
    "                            print(f\"  Average intensity in inner border (edge inside): {avg_inner:.2f}\")\n",
    "                            print(f\"  Average intensity in outer border (edge outside): {avg_outer:.2f}\")\n",
    "                            print(\"-\" * 50)\n",
    "                        \n",
    "                        # Compute intensity profile\n",
    "                        bins, intensity_profile, bin_masks = compute_intensity_profile(enhanced_image, mask, inner_pixels=6, outer_pixels=10)\n",
    "\n",
    "                        # Step 1: Compute the mean intensity for bins 6 to 10\n",
    "                        ref_bins = np.arange(8, 12)  # Bins from 6 to 10\n",
    "                        # Use numpy for safe indexing\n",
    "                        ref_indices = np.where(np.isin(bins, ref_bins))[0]\n",
    "                        ref_intensities = [intensity_profile[i] for i in ref_indices]\n",
    "                        mean_ref_intensity = np.mean(ref_intensities)\n",
    "\n",
    "                        # Step 2: Identify bins where intensity is lower than mean_ref_intensity\n",
    "                        composite_mask = np.zeros_like(mask)  # Initialize empty mask\n",
    "                        for i, intensity in enumerate(intensity_profile):\n",
    "                            bin_idx = bins[i]\n",
    "                            if intensity < mean_ref_intensity - 4:  # Threshold for lower intensity\n",
    "                                composite_mask = cv2.bitwise_or(composite_mask, bin_masks[bin_idx])\n",
    "\n",
    "                        # Step 3: Identify pixels in composite border that have intensity < mean_ref_intensity\n",
    "                        gray = cv2.cvtColor(enhanced_image, cv2.COLOR_BGR2GRAY)\n",
    "                        low_intensity_mask = (composite_mask == 255) & (gray < mean_ref_intensity)\n",
    "\n",
    "                        # Step 4: Count and calculate percentage\n",
    "                        low_intensity_pixel_count = np.sum(low_intensity_mask)\n",
    "                        total_composite_pixels = np.sum(composite_mask == 255)\n",
    "                        low_intensity_percentage = (low_intensity_pixel_count / total_composite_pixels) * 100 if total_composite_pixels > 0 else 0\n",
    "\n",
    "                        if VISUALIZE_PLOTS:\n",
    "                            print(f\"Percentage of low-intensity pixels in composite border: {low_intensity_percentage:.2f}%\")\n",
    "\n",
    "                        # Compute the percentage\n",
    "                        total_relevant_pixels = filled_pixel_count + low_intensity_pixel_count\n",
    "                        low_intensity_percentage = (low_intensity_pixel_count / total_relevant_pixels) * 100 if total_relevant_pixels > 0 else 0\n",
    "\n",
    "                        # print(filled_pixel_count, low_intensity_pixel_count, total_relevant_pixels, low_intensity_percentage)\n",
    "\n",
    "                        if VISUALIZE_PLOTS:\n",
    "                            print(f\"Percentage of low-intensity pixels in outer region of : {low_intensity_percentage:.2f}%\")\n",
    "\n",
    "                        # Step 5: Visualize the composite mask and low-intensity pixels\n",
    "\n",
    "                        if VISUALIZE_PLOTS:\n",
    "                            marked = enhanced_image.copy()\n",
    "                            marked[low_intensity_mask] = (0, 0, 255)  # Mark low-intensity pixels in red\n",
    "                            plt.subplot(1, 4, 4)\n",
    "                            plt.imshow(cv2.cvtColor(marked, cv2.COLOR_BGR2RGB))\n",
    "                            plt.title(\"Low Intensity Pixels in Composite Border\")\n",
    "                            plt.axis(\"off\")\n",
    "                            plt.show()\n",
    "                            \n",
    "                            # Plot the intensity profile\n",
    "                            plt.figure(figsize=(8, 5))\n",
    "                            plt.plot(bins, intensity_profile, marker='o', linestyle='-')\n",
    "                            plt.xlabel('Distance (pixels)\\n(Negative: inside, 0: boundary, Positive: outside)')\n",
    "                            plt.ylabel('Average Grayscale Intensity')\n",
    "                            plt.title(f'Intensity Profile Across Border')\n",
    "                            plt.grid(True)\n",
    "                            plt.show()\n",
    "\n",
    "                        # Step 6: Predict lateral seal\n",
    "                        if low_intensity_percentage > 0:\n",
    "                            pred_label = \"Incorrect\"\n",
    "                        else:\n",
    "                            pred_label = \"Correct\"\n",
    "                        \n",
    "                        # check ground truth\n",
    "                        gt = ann.get(\"lateral_seal\", \"\").strip().lower()\n",
    "                        if gt == \"correct\":\n",
    "                            y_true.append(\"Correct\")\n",
    "                            y_pred.append(pred_label)\n",
    "                        elif gt == \"incorrect\":\n",
    "                            y_true.append(\"Incorrect\")\n",
    "                            y_pred.append(pred_label)\n",
    "                        else:\n",
    "                            continue  # skip if no label\n",
    "\n",
    "    # Compute metrics\n",
    "    def compute_metrics(y_true, y_pred, label):\n",
    "        tp = sum((yt == label and yp == label) for yt, yp in zip(y_true, y_pred))\n",
    "        fp = sum((yt != label and yp == label) for yt, yp in zip(y_true, y_pred))\n",
    "        fn = sum((yt == label and yp != label) for yt, yp in zip(y_true, y_pred))\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        return precision, recall, f1, tp, fp, fn\n",
    "\n",
    "    correct_prec, correct_rec, correct_f1, tp1, fp1, fn1 = compute_metrics(y_true, y_pred, \"Correct\")\n",
    "    incorr_prec, incorr_rec, incorr_f1, tp2, fp2, fn2 = compute_metrics(y_true, y_pred, \"Incorrect\")\n",
    "    accuracy = sum(yt == yp for yt, yp in zip(y_true, y_pred)) / len(y_true) if y_true else 0\n",
    "    print(\"\\nLateral Seal Classification Metrics:\")\n",
    "    print(f\"Correct:    Precision={correct_prec:.3f}, Recall={correct_rec:.3f}, F1={correct_f1:.3f}, TP={tp1}, FP={fp1}, FN={fn1}\")\n",
    "    print(f\"Incorrect:  Precision={incorr_prec:.3f}, Recall={incorr_rec:.3f}, F1={incorr_f1:.3f}, TP={tp2}, FP={fp2}, FN={fn2}\")\n",
    "    print(f\"Overall Accuracy: {accuracy:.3f} ({sum(yt == yp for yt, yp in zip(y_true, y_pred))}/{len(y_true)})\")\n",
    "                        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cf8037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the original JSON data\n",
    "with open('annotated_and_labeled.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Function to count \"name\": \"Filling\" in an object\n",
    "def count_filling(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return sum(\n",
    "            1 for k, v in obj.items()\n",
    "            if (k == \"name\" and v == \"Filling\")\n",
    "        ) + sum(count_filling(v) for v in obj.values())\n",
    "    elif isinstance(obj, list):\n",
    "        return sum(count_filling(item) for item in obj)\n",
    "    return 0\n",
    "\n",
    "# Filter out objects with exactly 3 \"name\": \"Filling\"\n",
    "if isinstance(data, list):\n",
    "    filtered = [\n",
    "        obj for obj in data\n",
    "        if count_filling(obj) != 3\n",
    "    ]\n",
    "elif isinstance(data, dict):\n",
    "    # If the root is a dict, filter its values if they are lists of objects\n",
    "    filtered = {\n",
    "        k: [\n",
    "            obj for obj in v\n",
    "            if count_filling(obj) != 3\n",
    "        ] if isinstance(v, list) else v\n",
    "        for k, v in data.items()\n",
    "    }\n",
    "else:\n",
    "    raise ValueError(\"Unexpected JSON structure\")\n",
    "\n",
    "# Write the filtered data to a new file\n",
    "with open('annotated_and_labled_no_3.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(filtered, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Filtered JSON written to annotated_and_labled_no_3.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625747a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "VISUALIZE_PLOTS = False  # Set to True to enable visualization\n",
    "\n",
    "def load_annotations(json_file):\n",
    "    \"\"\"Load the annotation JSON file.\"\"\"\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\"Load an image from the given path.\"\"\"\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        print(\"Error loading image:\", image_path)\n",
    "    return img\n",
    "\n",
    "def apply_clahe_color(image, clip_limit=2.0, tile_grid_size=(8,8)):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    cl = clahe.apply(l)\n",
    "    limg = cv2.merge((cl, a, b))\n",
    "    enhanced = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "    return enhanced\n",
    "\n",
    "def scale_points(points, orig_width, orig_height):\n",
    "    scaled = []\n",
    "    for pt in points:\n",
    "        x = int(pt[0])\n",
    "        y = int(pt[1])\n",
    "        scaled.append([x, y])\n",
    "    return scaled\n",
    "\n",
    "def create_mask_for_polygon(img_shape, points):\n",
    "    pts = np.array(points, dtype=np.int32)\n",
    "    mask = np.zeros(img_shape[:2], dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, [pts], 255)\n",
    "    return mask\n",
    "\n",
    "def create_border_regions(mask, range_pixels):\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    eroded = cv2.erode(mask, kernel, iterations=range_pixels)\n",
    "    dilated = cv2.dilate(mask, kernel, iterations=range_pixels)\n",
    "    inner_border = cv2.subtract(mask, eroded)\n",
    "    outer_border = cv2.subtract(dilated, mask)\n",
    "    return inner_border, outer_border\n",
    "\n",
    "def analyze_intensities(image, mask, inner_border, outer_border):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    filling_values = gray[mask == 255]\n",
    "    inner_values = gray[inner_border == 255]\n",
    "    outer_values = gray[outer_border == 255]\n",
    "    avg_filling = np.mean(filling_values) if filling_values.size > 0 else 0\n",
    "    avg_inner = np.mean(inner_values) if inner_values.size > 0 else 0\n",
    "    avg_outer = np.mean(outer_values) if outer_values.size > 0 else 0\n",
    "    return avg_filling, avg_inner, avg_outer\n",
    "\n",
    "def overlay_annotation(image, points, color=(0, 255, 0), alpha=0.4):\n",
    "    overlay = image.copy()\n",
    "    pts = np.array(points, dtype=np.int32)\n",
    "    cv2.fillPoly(overlay, [pts], color)\n",
    "    combined = cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0)\n",
    "    return combined\n",
    "\n",
    "def overlay_mask(image, mask, color=(255, 0, 0), alpha=0.4):\n",
    "    overlay = image.copy()\n",
    "    overlay[mask == 255] = color\n",
    "    combined = cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0)\n",
    "    return combined\n",
    "\n",
    "def mark_low_intensity_pixels(image, outer_mask, threshold=200, mark_color=(0, 0, 255), alpha=0.5):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    low_intensity_mask = (outer_mask == 255) & (gray < threshold)\n",
    "    low_intensity_pixel_count = np.sum(low_intensity_mask)\n",
    "    marked = image.copy()\n",
    "    marked[low_intensity_mask] = mark_color\n",
    "    combined = cv2.addWeighted(marked, alpha, image, 1 - alpha, 0)\n",
    "    return combined, low_intensity_pixel_count\n",
    "\n",
    "def compute_intensity_profile(image, mask, inner_pixels=8, outer_pixels=10):\n",
    "    bins = np.arange(-inner_pixels, outer_pixels + 1, 1)\n",
    "    intensity_profile = []\n",
    "    bin_masks = {}\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    for b in bins:\n",
    "        if b < 0:\n",
    "            eroded_1 = cv2.erode(mask, kernel, iterations=abs(b))\n",
    "            border_1 = cv2.subtract(mask, eroded_1)\n",
    "            eroded_2 = cv2.erode(mask, kernel, iterations=abs(b) + 1)\n",
    "            border_2 = cv2.subtract(mask, eroded_2)\n",
    "            border = cv2.subtract(border_1, border_2)\n",
    "        else:\n",
    "            dilated_1 = cv2.dilate(mask, kernel, iterations=b)\n",
    "            border_1 = cv2.subtract(dilated_1, mask)\n",
    "            dilated_2 = cv2.dilate(mask, kernel, iterations=b + 1)\n",
    "            border_2 = cv2.subtract(dilated_2, mask)\n",
    "            border = cv2.subtract(border_2, border_1)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        values = gray[border == 255]\n",
    "        mean_intensity = np.mean(values) if values.size > 0 else 0\n",
    "        intensity_profile.append(mean_intensity)\n",
    "        bin_masks[b] = border\n",
    "    return bins, intensity_profile, bin_masks\n",
    "\n",
    "def visualize(image_path, annotations, title=\"\"):\n",
    "    image = Image.open(image_path)\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(title)\n",
    "    for ann in annotations:\n",
    "        shape = ann.get(\"shape\")\n",
    "        coords = ann.get(\"annotations\", [])\n",
    "        name = ann.get(\"name\")\n",
    "        if shape == \"polygon\" and name == \"Filling\" and len(coords) >= 4:\n",
    "            points = [(coords[i], coords[i+1]) for i in range(0, len(coords), 2)]\n",
    "            poly = patches.Polygon(points, closed=True, fill=False, edgecolor='red', linewidth=2)\n",
    "            ax.add_patch(poly)\n",
    "            ax.text(points[0][0], points[0][1], name, color='red', fontsize=9)\n",
    "            lateral_seal = ann.get(\"lateral_seal\", \"\")\n",
    "            if lateral_seal:\n",
    "                ax.text(points[0][0], points[0][1]+15, f\"Lateral Seal: {lateral_seal}\", color='blue', fontsize=8)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    # Define file names and parameters\n",
    "    json_file = \"annotated_and_labeled.json\"\n",
    "    image_dir = \"annotated_and_labeled\"\n",
    "    range_pixels = 10\n",
    "    data = load_annotations(json_file)\n",
    "    print(f\"Loaded {len(data)} entries from {json_file}\")\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    # Track how many ground truth labels are found\n",
    "    gt_count = 0\n",
    "\n",
    "    for entry in data:\n",
    "        # for ann in entry.get(\"annotation\", []):\n",
    "        #     if \"lateral_seal\" in ann:\n",
    "        #         print(f\"{entry.get('image_name', 'NO_IMAGE_NAME')}: {ann['lateral_seal']}\")\n",
    "        #         break\n",
    "\n",
    "        annotations = entry.get(\"annotation\", [])\n",
    "        has_valid_filling = any(\n",
    "            ann.get(\"shape\") == \"polygon\" and \n",
    "            ann.get(\"name\") == \"Filling\" and \n",
    "            len(ann.get(\"annotations\", [])) >= 4\n",
    "            for ann in annotations\n",
    "        )\n",
    "\n",
    "        if has_valid_filling:\n",
    "            img_path = os.path.join(image_dir, entry[\"image_name\"])\n",
    "            if os.path.exists(img_path) and VISUALIZE_PLOTS:\n",
    "                visualize(img_path, annotations, title=entry[\"image_name\"])\n",
    "\n",
    "        if not has_valid_filling:\n",
    "            print(f\"No valid filling annotations found for {entry['image_name']}\")\n",
    "            for ann in annotations:\n",
    "                print(ann.get(\"shape\"), ann.get(\"name\"), len(ann.get(\"annotations\", [])))\n",
    "            continue\n",
    "\n",
    "        if has_valid_filling:\n",
    "            img_path = os.path.join(image_dir, entry[\"image_name\"])\n",
    "            if os.path.exists(img_path):\n",
    "                image = load_image(img_path)\n",
    "                enhanced_image = apply_clahe_color(image)\n",
    "                results = []\n",
    "                for ann in annotations:\n",
    "                    shape = ann.get(\"shape\")\n",
    "                    coords = ann.get(\"annotations\", [])\n",
    "                    name = ann.get(\"name\")\n",
    "                    if shape == \"polygon\" and name == \"Filling\" and len(coords) >= 4:\n",
    "                        points = coords\n",
    "                        points_xy = [[points[i], points[i+1]] for i in range(0, len(points), 2)]\n",
    "                        scaled_points = scale_points(points_xy, image.shape[1], image.shape[0])\n",
    "                        mask = create_mask_for_polygon(image.shape, scaled_points)\n",
    "                        inner_border, outer_border = create_border_regions(mask, range_pixels)\n",
    "                        avg_filling, avg_inner, avg_outer = analyze_intensities(enhanced_image, mask, inner_border, outer_border)\n",
    "                        results.append({\n",
    "                            'label': name,\n",
    "                            'avg_filling': avg_filling,\n",
    "                            'avg_inner': avg_inner,\n",
    "                            'avg_outer': avg_outer,\n",
    "                            'mask': mask,\n",
    "                            'inner_border': inner_border,\n",
    "                            'outer_border': outer_border,\n",
    "                            'scaled_points': scaled_points\n",
    "                        })\n",
    "                        annotated_img = overlay_annotation(enhanced_image, scaled_points, color=(0, 255, 0), alpha=0.4)\n",
    "                        outer_edge_overlay = overlay_mask(enhanced_image, outer_border, color=(255, 0, 0), alpha=0.4)\n",
    "                        low_intensity_marked, low_intensity_pixel_count = mark_low_intensity_pixels(\n",
    "                            enhanced_image, outer_border, threshold=160, mark_color=(0, 0, 255), alpha=0.6\n",
    "                        )\n",
    "                        filled_pixel_count = np.sum(mask == 255)\n",
    "                        if VISUALIZE_PLOTS:\n",
    "                            plt.figure(figsize=(36, 10))\n",
    "                            plt.subplot(1, 4, 1)\n",
    "                            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "                            plt.title(\"Original Image\")\n",
    "                            plt.axis(\"off\")\n",
    "                            plt.subplot(1, 4, 2)\n",
    "                            plt.imshow(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))\n",
    "                            plt.title(f\"Annotation Filled \")\n",
    "                            plt.axis(\"off\")\n",
    "                            plt.subplot(1, 4, 3)\n",
    "                            plt.imshow(cv2.cvtColor(outer_edge_overlay, cv2.COLOR_BGR2RGB))\n",
    "                            plt.title(f\"Outer Edge Region \")\n",
    "                            plt.axis(\"off\")\n",
    "                            print(f\"Results for:\")\n",
    "                            print(f\"  Average intensity in filling region: {avg_filling:.2f}\")\n",
    "                            print(f\"  Average intensity in inner border (edge inside): {avg_inner:.2f}\")\n",
    "                            print(f\"  Average intensity in outer border (edge outside): {avg_outer:.2f}\")\n",
    "                            print(\"-\" * 50)\n",
    "                        bins, intensity_profile, bin_masks = compute_intensity_profile(enhanced_image, mask, inner_pixels=8, outer_pixels=10)\n",
    "                        ref_bins = np.arange(7, 11)\n",
    "                        ref_indices = np.where(np.isin(bins, ref_bins))[0]\n",
    "                        ref_intensities = [intensity_profile[i] for i in ref_indices]\n",
    "                        mean_ref_intensity = np.mean(ref_intensities)\n",
    "                        composite_mask = np.zeros_like(mask)\n",
    "                        for i, intensity in enumerate(intensity_profile):\n",
    "                            bin_idx = bins[i]\n",
    "                            if intensity < mean_ref_intensity - 4:\n",
    "                                composite_mask = cv2.bitwise_or(composite_mask, bin_masks[bin_idx])\n",
    "                        gray = cv2.cvtColor(enhanced_image, cv2.COLOR_BGR2GRAY)\n",
    "                        low_intensity_mask = (composite_mask == 255) & (gray < mean_ref_intensity)\n",
    "                        low_intensity_pixel_count = np.sum(low_intensity_mask)\n",
    "                        total_composite_pixels = np.sum(composite_mask == 255)\n",
    "                        low_intensity_percentage = (low_intensity_pixel_count / total_composite_pixels) * 100 if total_composite_pixels > 0 else 0\n",
    "                        if VISUALIZE_PLOTS:\n",
    "                            print(f\"Percentage of low-intensity pixels in composite border: {low_intensity_percentage:.2f}%\")\n",
    "                        total_relevant_pixels = filled_pixel_count + low_intensity_pixel_count\n",
    "                        low_intensity_percentage = (low_intensity_pixel_count / total_relevant_pixels) * 100 if total_relevant_pixels > 0 else 0\n",
    "                        if VISUALIZE_PLOTS:\n",
    "                            print(f\"Percentage of low-intensity pixels in outer region of : {low_intensity_percentage:.2f}%\")\n",
    "                        if VISUALIZE_PLOTS:\n",
    "                            marked = enhanced_image.copy()\n",
    "                            marked[low_intensity_mask] = (0, 0, 255)\n",
    "                            plt.subplot(1, 4, 4)\n",
    "                            plt.imshow(cv2.cvtColor(marked, cv2.COLOR_BGR2RGB))\n",
    "                            plt.title(\"Low Intensity Pixels in Composite Border\")\n",
    "                            plt.axis(\"off\")\n",
    "                            plt.show()\n",
    "                            plt.figure(figsize=(8, 5))\n",
    "                            plt.plot(bins, intensity_profile, marker='o', linestyle='-')\n",
    "                            plt.xlabel('Distance (pixels)\\n(Negative: inside, 0: boundary, Positive: outside)')\n",
    "                            plt.ylabel('Average Grayscale Intensity')\n",
    "                            plt.title(f'Intensity Profile Across Border')\n",
    "                            plt.grid(True)\n",
    "                            plt.show()\n",
    "                        if low_intensity_percentage > 0:\n",
    "                            pred_label = \"Incorrect\"\n",
    "                        else:\n",
    "                            pred_label = \"Correct\"\n",
    "                        gt = ann.get(\"lateral_seal\", \"\").strip().lower()\n",
    "                        # Only count if ground truth is present\n",
    "                        if gt == \"correct\":\n",
    "                            y_true.append(\"Correct\")\n",
    "                            y_pred.append(pred_label)\n",
    "                            gt_count += 1\n",
    "                        elif gt == \"incorrect\":\n",
    "                            y_true.append(\"Incorrect\")\n",
    "                            y_pred.append(pred_label)\n",
    "                            gt_count += 1\n",
    "                        else:\n",
    "                            # If no label, skip and warn\n",
    "                            continue\n",
    "\n",
    "    # If no ground truth labels were found, explain why metrics are empty\n",
    "    if gt_count == 0:\n",
    "        print(\"\\nNo ground truth 'lateral_seal' labels found in the data. Metrics cannot be computed.\")\n",
    "        print(\"Please check that your annotation JSON contains 'lateral_seal' fields with values 'Correct' or 'Incorrect'.\")\n",
    "        return\n",
    "\n",
    "    def compute_metrics(y_true, y_pred, label):\n",
    "        tp = sum((yt == label and yp == label) for yt, yp in zip(y_true, y_pred))\n",
    "        fp = sum((yt != label and yp == label) for yt, yp in zip(y_true, y_pred))\n",
    "        fn = sum((yt == label and yp != label) for yt, yp in zip(y_true, y_pred))\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        return precision, recall, f1, tp, fp, fn\n",
    "\n",
    "    correct_prec, correct_rec, correct_f1, tp1, fp1, fn1 = compute_metrics(y_true, y_pred, \"Correct\")\n",
    "    incorr_prec, incorr_rec, incorr_f1, tp2, fp2, fn2 = compute_metrics(y_true, y_pred, \"Incorrect\")\n",
    "    accuracy = sum(yt == yp for yt, yp in zip(y_true, y_pred)) / len(y_true) if y_true else 0\n",
    "    print(\"\\nLateral Seal Classification Metrics:\")\n",
    "    print(f\"Correct:    Precision={correct_prec:.3f}, Recall={correct_rec:.3f}, F1={correct_f1:.3f}, TP={tp1}, FP={fp1}, FN={fn1}\")\n",
    "    print(f\"Incorrect:  Precision={incorr_prec:.3f}, Recall={incorr_rec:.3f}, F1={incorr_f1:.3f}, TP={tp2}, FP={fp2}, FN={fn2}\")\n",
    "    print(f\"Overall Accuracy: {accuracy:.3f} ({sum(yt == yp for yt, yp in zip(y_true, y_pred))}/{len(y_true)})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
